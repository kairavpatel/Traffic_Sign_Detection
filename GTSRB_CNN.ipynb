{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GTSRB_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMCD8v3fHiPO"
      },
      "source": [
        " #Verify the GPU \n",
        "import tensorflow as tf \n",
        "tf.test.gpu_device_name()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT86NG0YMCMz"
      },
      "source": [
        "##Open Cv version\n",
        "import cv2\n",
        "cv2.__version__                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJMS1xGOSHiD"
      },
      "source": [
        "##Installing the Tensorflow\n",
        "!pip install tensorflow==2.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEM5gnYUTzGy"
      },
      "source": [
        "##Check Tensorflow version\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60mT4DeB4Un"
      },
      "source": [
        "##Upload the Kaggle credentials File (Kaggle.json)\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4pLnlrZW8XE"
      },
      "source": [
        "## Execute the Kaggle Json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqqTu68mXFEl"
      },
      "source": [
        "## Download the German Traffic Sign Dataset(GTSRD)\n",
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmsTNWJxXaXC"
      },
      "source": [
        "##Unzip The GTSRD Data\n",
        "!unzip /content/gtsrb-german-traffic-sign.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5DudpNXprs"
      },
      "source": [
        "##Import Data\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Train.csv')\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEsVdWQ0aSHn"
      },
      "source": [
        "##Create the Data Array and Array of Labels\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "data = []\n",
        "labels = []\n",
        "path = np.array(df.Path)\n",
        "for i in path:\n",
        "            image = cv2.imread(i)\n",
        "            image_from_array = Image.fromarray(image, 'RGB')\n",
        "            size_image = image_from_array.resize((32, 32))\n",
        "            data.append(np.array(size_image))\n",
        "            labels.append(i.split('/')[1])\n",
        "Cells=np.array(data)\n",
        "labels=np.array(labels)\n",
        "#print('Labels_shape',labels.shape)\n",
        "#print('Cells_shape',Cells.shape)\n",
        "plt.imshow(Cells[8025])  ##Example 8025\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXRzzQWFwr7X"
      },
      "source": [
        "## Color Intensity of Image\n",
        "import cv2 as cv\n",
        "color = ('b','g','r')\n",
        "for i,col in enumerate(color):\n",
        "    histr = cv.calcHist([Cells[8025]],[i],None,[256],[0,256])\n",
        "    plt.plot(histr,color = col)\n",
        "    plt.xlim([0,256])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9exjiRhu07d"
      },
      "source": [
        "##Without Color Intensity V/s Pixels\n",
        "plt.hist(Cells[8025].ravel(),256,[0,256])\n",
        "hist,bins = np.histogram(Cells[8025].ravel(),256,[0,256])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhhOSpr77wrz"
      },
      "source": [
        "##Image Processing Functions \n",
        "import cv2\n",
        "def grayscale(img):\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  return img\n",
        "\n",
        "def equilizer(img):\n",
        "  img = cv2.equalizeHist(img)\n",
        "  return img\n",
        "\n",
        "def preprocessing(img):\n",
        "  img = grayscale(img)\n",
        "  img = equilizer(img)\n",
        "  img = img / 255\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOoNuJRhHkWs"
      },
      "source": [
        "##Plot Each Category of the Data\n",
        "import matplotlib.pyplot as plt\n",
        "sample = pd.read_csv('Meta.csv')\n",
        "sample_data = sample.ClassId\n",
        "num = []\n",
        "fig=plt.figure(figsize=(10,10))\t\n",
        "plt.title(\"Traffic_Sign_Samples\",color='black', pad = 45)\n",
        "plt.axis(False)\n",
        "for i in range(43):\n",
        "\t sum = 0\n",
        "\t ax = fig.add_subplot(7, 7, i+1)\n",
        "\t ax.imshow(cv2.imread('/content/meta/{}.png'.format(i)))\n",
        "\t ax.set_title(i, color ='black')\n",
        "\t plt.xticks([])\n",
        "\t plt.yticks([])\n",
        "\t plt.tight_layout()\n",
        "plt.savefig('Sample_data.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qIPW19JWmpV"
      },
      "source": [
        "##Ploting the Data Distribuction \n",
        "values = pd.value_counts(labels).keys().tolist()\n",
        "counts = pd.value_counts(labels).tolist()\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.bar(values, counts,color='#444444')\n",
        "plt.title(\"Distribution of the Train Dataset\",color='black')\n",
        "plt.xlabel(\"Data Catagories\",color='black')\n",
        "plt.ylabel(\"Number of images\",color='black')\n",
        "plt.grid(True)\n",
        "plt.savefig('Data_Distribuction.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJZuhRfNLY2e"
      },
      "source": [
        "##Preprocessing the Data before going to Training \n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "data_new_train = np.array(list(map(preprocessing,Cells)))\n",
        "print(data_new_train.shape)\n",
        "plt.imshow(data_new_train[8025],cmap = 'gray')\n",
        "plt.axis('off')\n",
        "#plt.savefig('Data.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrpEBgR6iAJH"
      },
      "source": [
        "##Reshape the Data for the Requirements\n",
        "data_new_train = data_new_train.reshape(39209,32,32,1)\n",
        "#Spliting the images into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(data_new_train, labels, test_size=0.2, random_state=42, shuffle=True)\n",
        "print('train_data',train_x.shape)\n",
        "print('Valid_data',val_x.shape)\n",
        "print('train_data_label',train_y.shape)\n",
        "print('Val_data_label',val_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBeRABJwxcPW"
      },
      "source": [
        "#Using one hote encoding for the train and validation labels\n",
        "from keras.utils import to_categorical\n",
        "train_y = to_categorical(train_y, 43)\n",
        "val_y = to_categorical(val_y, 43)\n",
        "print('Train_data_label_shape',train_y.shape)\n",
        "print('Validation_data_label_shape',val_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCzTFhMJwQ2X"
      },
      "source": [
        "#Model's (1-7)\n",
        "choose only one model to predict the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is63YMYXHVLk"
      },
      "source": [
        "##1.Base_line_Model (TSR-CNN)\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer = 'he_uniform'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "# compile model\n",
        "with open('TSR_CNN.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqqS-O1dI95l"
      },
      "source": [
        "##2.TSR-CNN-1\n",
        "##Base_Line_Model (TSR-CNN) + Weight_decay_model\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "# compile model\n",
        "with open('TSR_CNN_1.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-8zhQ4pIAq7"
      },
      "source": [
        "##3.TSR-CNN-2\n",
        "##Base_line (TSR-CNN) + Dropout_model\t\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "#model.add(Dropout(0.02))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "# compile model\n",
        "with open('TSR_CNN_2.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RWDfPnjKgOA"
      },
      "source": [
        "##4.TSR-CNN-3\n",
        "##Base_line_Model + Variance_Dropout\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "# compile model\n",
        "with open('TSR_CNN_3.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy04hl5vipj"
      },
      "source": [
        "##5.TSR-CNN-4 \n",
        "##Base_line_Model + Batch Normalization\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#compile model\n",
        "with open('TSR_CNN_4.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzfjodJgiHtj"
      },
      "source": [
        "##6.TSR-CNN-5 \n",
        "##Base_line_Model + Dropout + Batch Normalization\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#compile model\n",
        "with open('TSR_CNN_5.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibr7rlolu8xR"
      },
      "source": [
        "##7.TSR-CNN-6 \n",
        "##Base_line_Model + Variance_Dropout + Batch Normalization\n",
        "from tensorflow.python.keras import Sequential\n",
        "from contextlib import redirect_stdout\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "#compile model\n",
        "with open('TSR_CNN_6.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB0LRO9z71rC"
      },
      "source": [
        "# Clear logs files from previous training to get new results \n",
        "!rm -rf ./log/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdorRAc_6q8T"
      },
      "source": [
        "##Tenssore board\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "log_dir = \"log/\" #atetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./log\")\n",
        "                                                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frmfKuZBiO3O"
      },
      "source": [
        "#Compilation of the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2 = 0.999, amsgrad=False)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JroAJQVxIFv"
      },
      "source": [
        "#Train the Model\n",
        "epochs = 5\n",
        "history = model.fit(train_x, train_y, batch_size = 64, epochs = epochs,shuffle= True, validation_data=(val_x, val_y),callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quWJpaJdgAiR"
      },
      "source": [
        "## See the Loss and Accuracy in Tensorboard\n",
        "#!pip install -U tensorboard\n",
        "!tensorboard dev upload --logdir {\"./log\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQoOlJM7ta-H"
      },
      "source": [
        "##Plotting the Graph of the Loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "#plt.subplot(211)\n",
        "plt.figure(1)\n",
        "plt.title('Loss')\n",
        "plt.xlabel(\"Epochs\",color='black')\n",
        "plt.ylabel(\"Loss\",color='black')\n",
        "plt.plot(history.history['loss'],color = 'green',label = 'Train_Loss')\n",
        "plt.plot(history.history['val_loss'],color = 'black',label = 'Val_Loss')\n",
        "plt.legend()\n",
        "plt.savefig('Loss_Baseline.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x4buCO6tkS6"
      },
      "source": [
        "## Accuracy Curve\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.title('Cross_Entropy_Accuracy')\n",
        "plt.xlabel(\"Epochs\",color='black')\n",
        "plt.ylabel(\"Accuracy\",color='black')\n",
        "plt.plot(history.history['accuracy'],color = 'green',label = 'Train_Acc')\n",
        "plt.plot(history.history['val_accuracy'],color = 'black',label = 'Val_Acc')\n",
        "plt.legend()\n",
        "plt.savefig('Accuracy_Baseline.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Ww-HEwjCxz"
      },
      "source": [
        "##Pre-process test-data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "#Predicting with the test data\n",
        "test_y = pd.read_csv(\"Test.csv\")\n",
        "#labels=y_test['Path'].as_matrix()\n",
        "test_labels = test_y['ClassId'].values\n",
        "test_data = []\n",
        "path_test = np.array(test_y.Path)\n",
        "for i in path_test:\n",
        "            image=cv2.imread(i)\n",
        "            image_from_array = Image.fromarray(image, 'RGB')\n",
        "            size_image = image_from_array.resize((32, 32))\n",
        "            test_data.append(np.array(size_image))\n",
        "test_data = np.array(test_data)\n",
        "test_data = np.array(list(map(preprocessing,test_data)))\n",
        "test_data = np.array(test_data).astype(np.float32)\n",
        "test_labels = np.array(test_labels)\n",
        "##Shape of the Test Data\n",
        "#print(test_data.shape)\n",
        "print('Test_data_Shape',test_data.shape)\n",
        "print('Test_label_shape',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVKzwVbHpmha"
      },
      "source": [
        "##Test_example data for prediction\n",
        "plt.axis('off')\n",
        "plt.imshow(test_data[12],cmap='gray')\n",
        "print('Test_data_Label:', test_labels[12])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QZRTi2yyNyx"
      },
      "source": [
        "##Prediction the Sample Data\n",
        "#Convert as per requirements\n",
        "test_data = test_data.reshape(12630,32,32,1)\n",
        "##Predict the model\n",
        "predict  = model.predict_classes(test_data)\n",
        "print('Prediction label of above example (12) :', predict[12])\n",
        "##auucracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Total accuracy of the model', accuracy_score(test_labels,predict))\n",
        "\n",
        "##Plot the prediction graph\n",
        "#pred = model.predict(test_data.reshape(12630,32,32,1))\n",
        "#y = list(pred[12])\n",
        "#y_1 = [i*1000000 for i in y]\n",
        "#x = [i for i in range(43)]\n",
        "#print(y_1)\n",
        "#print(x)\n",
        "#plt.figure(figsize=(10, 5))\n",
        "#plt.style.use('fivethirtyeight')\n",
        "#plt.bar(x,y,color='#444444')\n",
        "#plt.title(\"Distribution of the Train Dataset\",color='black')\n",
        "#plt.xlabel(\"Data Catagories\",color='black')\n",
        "#plt.ylabel(\"Number of images\",color='black')\n",
        "#plt.grid(True)\n",
        "#plt.savefig('Data_Distribuction.png',bbox_inches='tight')\"\"\"\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "##Conver the Data As per Requirements\n",
        "#test_data = test_data.reshape(12630,32,32,1)\n",
        "#test_labels = to_categorical(test_labels, 43)\n",
        "#print('test_data',test_data.shape)\n",
        "#print('test_labels',test_labels.shape)\n",
        "#score = model.evaluate(test_data,test_labels,verbose=1)\n",
        "#print('Test_Score',score[0])\n",
        "#print('Test_Accuracy',score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-RUrecn5mkz"
      },
      "source": [
        "##Test the Image from the URL:\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "url = 'https://previews.123rf.com/images/pejo/pejo0907/pejo090700003/5155701-german-traffic-sign-no-205-give-way.jpg'#'https://previews.123rf.com/images/bwylezich/bwylezich1608/bwylezich160800375/64914157-german-road-sign-slippery-road.jpg'\n",
        "r = requests.get(url,stream = True)\n",
        "img = Image.open(r.raw)\n",
        "plt.axis('off')\n",
        "plt.imshow(img,cmap = 'gray' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTk4vAsVqeJ"
      },
      "source": [
        "## Predict the URL Data's\n",
        "img = np.asarray(img)\n",
        "img = cv2.resize(img,(32,32))\n",
        "data = np.array(img)\n",
        "data = data.reshape(1,32,32,3)\n",
        "data = np.array(list(map(preprocessing,data)))\n",
        "#plt.imshow(data[0],cmap='gray')\n",
        "#plt.axis('off')\n",
        "#plt.show()\n",
        "##Model Prediction\n",
        "#Resize as per requirments\n",
        "img = data.reshape(1,32,32,1)\n",
        "print('Testing image Class is :' + str(model.predict_classes(img)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdnQXKDNuxxR"
      },
      "source": [
        "##Confusion Matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(test_labels, predict))\n",
        "cnf_matrix = confusion_matrix(test_labels, predict)\n",
        "print(cnf_matrix)\n",
        "plt.savefig('l.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPeKeNcBukDt"
      },
      "source": [
        "# Plotting the confusion matrix\n",
        "import itertools\n",
        "names = [i for i in range(43)]\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion Matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label',labelpad=20)\n",
        "    plt.xlabel('Predicted label',labelpad=20)\n",
        "    plt.grid(False)\n",
        "plot_confusion_matrix(cnf_matrix, classes= names,title='Confusion matrix')\n",
        "plt.savefig('Confusion_Matrix_baseline.png',bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9CbBHpUGycS"
      },
      "source": [
        "##Summarize filter shapes\n",
        "for layer in model.layers:\n",
        "  # check for convolutional layer\n",
        "  if 'conv' not in layer.name:\n",
        "     continue\n",
        "  # Get Filter Weights\n",
        "  filters, biases = layer.get_weights()\n",
        "  print(layer.name,filters.shape,biases.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQa5VVcUIimz"
      },
      "source": [
        "## Visulization of the Some Filters \n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "# retrieve weights from the first hidden layer\n",
        "filters, biases = model.layers[0].get_weights()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "# plot first few filters\n",
        "n_filters, ix = 32,3  ## number of filter's and Layer number                    ## select the Layer here\n",
        "fig=pyplot.figure(figsize=(25,25))\t\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(1):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = fig.add_subplot(n_filters, 4, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "    \n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tpyplot.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.savefig(str(ix) + '_layer_weights.png',bbox_inches='tight')\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9CUnXituknD"
      },
      "source": [
        "## Activation output of Test _example (12)\n",
        "import theano\n",
        "from keras import backend as K\n",
        "from PIL import Image\n",
        "##Conver the Data As per Requirements\n",
        "test_image = test_data.reshape(12630,32,32)\n",
        "test_image = test_image[12] ## To change\n",
        "#print (test_image.shape)\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(test_image)\n",
        "plt.axis(False)\n",
        "plt.savefig('test.png',bbox_inches='tight')\n",
        "plt.show()\n",
        "##Convert the image to array\n",
        "#test_image = Image.fromarray(test_image)\n",
        "##Expand the image as per Requirements\n",
        "#test_image_f = np.expand_dims(test_image,axis=0)\n",
        "#test_image_f = test_image_f.reshape(1,32,32,1)\n",
        "#print(test_image_f.shape)##How the layer Visulize the image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tii5-kF1ojkF"
      },
      "source": [
        "## Keras Sample-output visulization\n",
        "from keras.models import Model\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
        "activations = activation_model.predict(test_image.reshape(1,32,32,1))\n",
        " \n",
        "def display_activation(activations, col_size, row_size, act_index): \n",
        "    activation = activations[act_index]\n",
        "    activation_index=0\n",
        "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
        "    for row in range(0,row_size):\n",
        "        for col in range(0,col_size):\n",
        "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
        "            ax[row][col].axis('off')\n",
        "            activation_index += 1\n",
        "    plt.savefig('test.png',bbox_inches='tight')\n",
        "## Display layer's and with filters \n",
        "## (filters, filters, Layer Number)\n",
        "display_activation(activations, 8, 8, 3)       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzqJOwIcdn3t"
      },
      "source": [
        "##To  Save  the Model in JSON Form\n",
        "model_json = model.to_json()\n",
        "with open('model.json','w') as json_file:\n",
        "      json_file.write(model_json)\n",
        "##To save the weight\n",
        "model.save_weights('model_weight_json.h5')\n",
        "print('Model has saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N52XxoLPfrlw"
      },
      "source": [
        "##To Load json Model\n",
        "from tensorflow.keras.models import model_from_json\n",
        "json_file  = open('model.json')\n",
        "load_model_json = json_file.read()\n",
        "json_file.close()\n",
        "##load\n",
        "model_1 = model_from_json(load_model_json)\n",
        "model_1.load_weights('model_weight_json.h5')\n",
        "print('Model has loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBjcxk5nhhIQ"
      },
      "source": [
        "##To save the model (YaMl)\n",
        "model_yaml  = model.to_yaml()\n",
        "with open('model.yaml','w') as yaml_file:\n",
        "  yaml_file.write(model_yaml)\n",
        "##To save the weight\n",
        "model.save_weights('model_weight_yaml.h5')\n",
        "\n",
        "print('Model has Saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLHF9_xsip3R"
      },
      "source": [
        "##To Load the model (YaMl)\n",
        "from tensorflow.keras.models import model_from_yaml\n",
        "yaml_file  = open('model.yaml')\n",
        "load_model_yaml  = yaml_file.read()\n",
        "yaml_file.close()\n",
        "\n",
        "##To load the weights\n",
        "model_2 = model_from_yaml(load_model_yaml)\n",
        "model_2.load_weights('model_weight_yaml.h5')\n",
        "print('Model has loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGrsrYsNjm8Y"
      },
      "source": [
        "##To Save model with HDF5\n",
        "model = model.save('final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6fC0iagkPUf"
      },
      "source": [
        "##To Load weights\n",
        "from tensorflow.keras.models import load_model\n",
        "model_3 = load_model('final_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}